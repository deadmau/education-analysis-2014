{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook, you'll\n",
      "\n",
      "* **load the raw data into R or Pandas dataframe** from the <code>./data/raw</code> directory using the functions and classes (written during the data gathering phase) in the <code>./script</code> directory\n",
      "\n",
      "\n",
      "* **perform visual exploration** on your data variables to detect anomalies, errors, outliers, interesting features etc.\n",
      "\n",
      "\n",
      "\n",
      "* **clean categorical and quantitative variables** (by removing observations and variables with too many missing values, by consolidating categorical variables, by selecting an appropriate subset of variables and observations for later analysis, etc.)\n",
      "\n",
      "\n",
      "* **save the cleaned data** into csv files in the <code>./data/cleaned</code> directory\n",
      "\n",
      "\n",
      "* **save interesting graphics** you obtained during visual exploration into the <code>./visualiation</code> directory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Team members responsible for this notebook:\n",
      "\n",
      "* **Armando**\n",
      "        Responsibilities: Completing this page"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Workflow:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "1) load the raw data into R or Pandas dataframe from the ./data/raw directory using the functions and classes (written during the data gathering phase) in the ./script directory"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- use script to parsecountries into 6 pickles - one for the US, one for south/central america, one for europe, one for africa, one for asia, one for all continents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%run ../script/StreamAnalysis/loadData.py\n",
      "\n",
      "locationDict = pd.read_pickle('../data/raw/locationtweets.pkl')\n",
      "nolocationSet = pd.read_pickle('../data/raw/nolocationtweets.pkl')\n",
      "totalSet = pd.read_pickle('../data/raw/totaltweets.pkl')\n",
      "\n",
      "#%run ../script/StreamAnalysis/parsecountries.py\n",
      "\n",
      "usSet = pd.read_pickle('../data/cleaned/ustweets.pkl')\n",
      "euroSet = pd.read_pickle('../data/cleaned/eutweets.pkl')\n",
      "asiaSet = pd.read_pickle('../data/cleaned/asiatweets.pkl')\n",
      "africaSet = pd.read_pickle('../data/cleaned/africatweets.pkl')\n",
      "southamericaSet = pd.read_pickle('../data/cleaned/soamericatweets.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Number of tweets: 297570\n",
        "Number of tweets with location data: 15244"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Number of tweets excluded for containing bad/improper data: 12\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- use script to make 6 word frequency csv files, one for all tweets and 5 for the US, europe, asia, africa, south/central america\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "# %run ../script/StreamAnalysis/parsewords.py\n",
      "\n",
      "totalWords = pd.read_pickle('../data/cleaned/totalwords.pkl')\n",
      "usWords = pd.read_pickle('../data/cleaned/uswords.pkl')\n",
      "euroWords = pd.read_pickle('../data/cleaned/euwords.pkl')\n",
      "asiaWords = pd.read_pickle('../data/cleaned/asiawords.pkl')\n",
      "africaWords = pd.read_pickle('../data/cleaned/africawords.pkl')\n",
      "southamericaWords = pd.read_pickle('../data/cleaned/soamericawords.pkl')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- use script to make 5 sentiment analyzed csv files for each continent DOES THAT HAPPEN HERE?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "perform visual exploration on your data variables to detect anomalies, errors, outliers, interesting features etc.\n",
      "\n",
      "- print out random tweets for each continent\n",
      "\n",
      "- print out top words for each continent"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Total number of tweets: \" + str(len(totalSet))\n",
      "print ''\n",
      "print \"Number of tweets with location data: \" + str(len(locationDict))\n",
      "print ''\n",
      "\n",
      "print \"Printing raw tweets with location...\\n\"\n",
      "locKeys = locationDict.keys()\n",
      "for key in (locKeys[0:5]):\n",
      "    print \"Text: \" + key + \", Location: \" + locationDict[key] + '\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "clean categorical and quantitative variables (by removing observations and variables with too many missing values, by consolidating categorical variables, by selecting an appropriate subset of variables and observations for later analysis, etc.)\n",
      "\n",
      "- remove single letter adjectives, and words like to, etc."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "save the cleaned data into csv files in the ./data/cleaned directory"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "save interesting graphics you obtained during visual exploration into the ./visualiation directory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Example"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here I'll load the plant data in xml format into a R data frame using the \n",
      "\n",
      "    create_df_from_plant_xml(file)\n",
      "    \n",
      "function contained in the R script \n",
      "\n",
      "        ./script/plant_df-R"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext rmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The rmagic extension is already loaded. To reload it, use:\n",
        "  %reload_ext rmagic\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To load the function into a R cell, one needs to use the\n",
      "\n",
      "    source(R_script_file)\n",
      "command in R, which works in a similar way as the \n",
      "\n",
      "    import module\n",
      "command in Python:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R \n",
      "\n",
      "source('./script/plant_df-R')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can create a data frame directly from the XML file using the functin contained in the scrip above.\n",
      "\n",
      "If you wish to perform the cleaning using Pandas data frames instead of R data frames, one make the R data frame available to Python cells by using the R magic command:\n",
      "\n",
      "    %%R -d df_name\n",
      "\n",
      "To know more on how to pass variables back and forth between R and Python cells, please have a look at the notebook [here](http://nbviewer.ipython.org/url/github.com/ipython/ipython/raw/master/examples/notebooks/R%20Magics.ipynb)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R -d data\n",
      "\n",
      "library(XML)\n",
      "\n",
      "data = create_df_from_plant_xml('./data/raw/plant.xml')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's load our data into a Pandas data frame:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame\n",
      "\n",
      "df = DataFrame(data)\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>COMMON</th>\n",
        "      <th>BOTANICAL</th>\n",
        "      <th>ZONE</th>\n",
        "      <th>LIGHT</th>\n",
        "      <th>PRICE</th>\n",
        "      <th>AVAILABILITY</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>           Bloodroot</td>\n",
        "      <td> Sanguinaria canadensis</td>\n",
        "      <td> 4</td>\n",
        "      <td> Mostly Shady</td>\n",
        "      <td> $2.44</td>\n",
        "      <td> 031599</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>           Columbine</td>\n",
        "      <td>   Aquilegia canadensis</td>\n",
        "      <td> 3</td>\n",
        "      <td> Mostly Shady</td>\n",
        "      <td> $9.37</td>\n",
        "      <td> 030699</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>      Marsh Marigold</td>\n",
        "      <td>       Caltha palustris</td>\n",
        "      <td> 4</td>\n",
        "      <td> Mostly Sunny</td>\n",
        "      <td> $6.81</td>\n",
        "      <td> 051799</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>             Cowslip</td>\n",
        "      <td>       Caltha palustris</td>\n",
        "      <td> 4</td>\n",
        "      <td> Mostly Shady</td>\n",
        "      <td> $9.90</td>\n",
        "      <td> 030699</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> Dutchman's-Breeches</td>\n",
        "      <td>    Dicentra cucullaria</td>\n",
        "      <td> 3</td>\n",
        "      <td> Mostly Shady</td>\n",
        "      <td> $6.44</td>\n",
        "      <td> 012099</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "                COMMON               BOTANICAL ZONE         LIGHT  PRICE AVAILABILITY\n",
        "0            Bloodroot  Sanguinaria canadensis    4  Mostly Shady  $2.44       031599\n",
        "1            Columbine    Aquilegia canadensis    3  Mostly Shady  $9.37       030699\n",
        "2       Marsh Marigold        Caltha palustris    4  Mostly Sunny  $6.81       051799\n",
        "3              Cowslip        Caltha palustris    4  Mostly Shady  $9.90       030699\n",
        "4  Dutchman's-Breeches     Dicentra cucullaria    3  Mostly Shady  $6.44       012099"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The actual data cleaning can now begins!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}